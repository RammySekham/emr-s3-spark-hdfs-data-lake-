{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"elt\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data1 = \"data/log-data/*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.json(input_data1, multiLine=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Login</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NextSong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page\n",
       "0      Home\n",
       "1     Login\n",
       "2  NextSong"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"page\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "dff = df.filter((col(\"page\") =='NextSong') & col(\"userId\").isNotNull()).groupby('userId').agg({'ts':'max'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- max(ts): long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl=df.join(dff, (df.ts==col(\"max(ts)\")) & (df.userId==dff.userId), 'right').select(df.userId.alias(\"user_id\"), col(\"firstName\").alias(\"first_name\"), \n",
    "                                             col(\"lastName\").alias(\"last_name\"), \"gender\", \"level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Break the problem in parts\n",
    "##Part-1 I need incremental songplay_id\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Getting normal columns from table \n",
    "dft=df.filter(\"page='NextSong'\")\n",
    "dft.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solving Timestamp problem\n",
    "# get_timestamp = udf()\n",
    "date_time = df.select(from_unixtime(col(\"ts\")/1000).alias('tsm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = dft.join(dfs,(dft.artist==dfs.artist_name) & (dft.song==dfs.title), 'left')\\\n",
    "    .select(from_unixtime(col(\"ts\")/1000).alias(\"start_time\"), col(\"userId\").alias(\"user_id\"), \"level\", dfs.song_id, dfs.artist_id,\\\n",
    "     col(\"sessionId\").alias(\"session_id\"), \"location\", col(\"userAgent\").alias(\"user_agent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "#start_time, hour, day, week, month, year, weekday\n",
    "time_table = date_time.select(col(\"tsm\").alias(\"start_time\"), hour(col(\"tsm\")).alias(\"hour\"), dayofmonth(col(\"tsm\")).alias(\"day\"),\\\n",
    "                             weekofyear(col(\"tsm\")).alias(\"week\"), month(col(\"tsm\")).alias(\"month\"), year(col(\"tsm\")).alias(\"year\"),\\\n",
    "                             dayofweek(col(\"tsm\")).alias(\"weekday\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|         start_time|hour|day|week|month|year|weekday|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-15 11:30:26|  11| 15|  46|   11|2018|      5|\n",
      "|2018-11-21 11:27:34|  11| 21|  47|   11|2018|      4|\n",
      "|2018-11-14 11:03:22|  11| 14|  46|   11|2018|      4|\n",
      "|2018-11-28 11:00:15|  11| 28|  48|   11|2018|      4|\n",
      "|2018-11-05 11:33:12|  11|  5|  45|   11|2018|      2|\n",
      "|2018-11-13 11:36:57|  11| 13|  46|   11|2018|      3|\n",
      "|2018-11-30 11:22:07|  11| 30|  48|   11|2018|      6|\n",
      "|2018-11-16 11:00:57|  11| 16|  46|   11|2018|      6|\n",
      "|2018-11-20 11:00:42|  11| 20|  47|   11|2018|      3|\n",
      "|2018-11-24 11:45:00|  11| 24|  47|   11|2018|      7|\n",
      "|2018-11-29 11:00:57|  11| 29|  48|   11|2018|      5|\n",
      "|2018-11-19 12:54:28|  12| 19|  47|   11|2018|      2|\n",
      "|2018-11-27 11:52:12|  11| 27|  48|   11|2018|      3|\n",
      "|2018-11-23 11:07:25|  11| 23|  47|   11|2018|      6|\n",
      "|2018-11-09 11:06:17|  11|  9|  45|   11|2018|      6|\n",
      "|2018-11-26 11:02:43|  11| 26|  48|   11|2018|      2|\n",
      "|2018-11-08 11:12:30|  11|  8|  45|   11|2018|      5|\n",
      "|2018-11-12 13:36:57|  13| 12|  46|   11|2018|      2|\n",
      "|2018-11-07 11:01:16|  11|  7|  45|   11|2018|      4|\n",
      "|2018-11-04 11:15:55|  11|  4|  44|   11|2018|      1|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Artist Table\n",
    "#artist_id, name, location, lattitude, longitude\n",
    "artist = dfs.filter(\"artist_id is NOT NULL\").select(\"artist_id\", col(\"artist_location\").alias(\"location\"), col(\"artist_latitude\").alias(\"latitude\"),\\\n",
    "           col(\"artist_longitude\").alias(\"longitude\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|         artist_id|max(year)|\n",
      "+------------------+---------+\n",
      "|AR9AWNF1187B9AB0B4|        0|\n",
      "+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a1 = dfs.alias(\"one\").filter(\"artist_id is NOT NULL\").groupby(\"artist_id\").agg({'year':'max'})\n",
    "a1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logic to get artist' latest details by year, \n",
    "## when artist has two updates per year, records are taken as sort order whichever appear first\n",
    "\n",
    "a2 = dfs.alias(\"one\").filter(\"artist_id is NOT NULL\").groupby(\"artist_id\").agg({'year':'max'})\\\n",
    ".join(dfs.alias(\"two\"), (col(\"one.artist_id\")==col(\"two.artist_id\")) & (col(\"max(year)\")==col(\"two.year\")), 'right')\\\n",
    ".select(\"one.artist_id\", col(\"artist_location\").alias(\"location\"), col(\"artist_latitude\").alias(\"latitude\"),\\\n",
    "           col(\"artist_longitude\").alias(\"longitude\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let us optimize query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Song Table\n",
    "dfs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
